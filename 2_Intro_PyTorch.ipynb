{"cells":[{"cell_type":"markdown","id":"perceived-donor","metadata":{"id":"perceived-donor"},"source":["# Introduction to PyTorch\n","\n","This notebook was adapted from [Stanford's CS224N Pytorch](https://github.com/SunnyHaze/Stanford-CS224N-NLP/blob/main/CS224N%20PyTorch%20Tutorial.ipynb) Tutorial by Dilara Soylu as well as the official [PyTorch 60 Minute Blitz Tutorial](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) demo for PyTorch.\n","\n","We will have a basic introduction to `PyTorch` and Tensors and how to use them to create, train and evaluate Neural Networks. In the end, we will build, train, and evaluate our first classifier by classifying two moons!"]},{"cell_type":"markdown","id":"static-african","metadata":{"id":"static-african"},"source":["## Introduction\n","[PyTorch](https://pytorch.org/) is a machine learning framework that is used in both academia and industry for various applications. PyTorch started of as a more flexible alternative to [TensorFlow](https://www.tensorflow.org/), which is another popular machine learning framework. At the time of its release, `PyTorch` appealed to the users due to its user friendly nature: as opposed to defining static graphs before performing an operation as in `TensorFlow`, `PyTorch` allowed users to define their operations as they go, which is also the approached integrated by `TensorFlow` in its following releases. Although `TensorFlow` is more widely preferred in the industry, `PyTorch` is often times the preferred machine learning framework for researchers.\n","\n","Now that we have learned enough about the background of `PyTorch`, let's start by importing it into our notebook."]},{"cell_type":"code","execution_count":8,"id":"hindu-wales","metadata":{"id":"hindu-wales","executionInfo":{"status":"ok","timestamp":1744881005355,"user_tz":-120,"elapsed":16,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn # contains functionality for building neural networks\n","import numpy as np"]},{"cell_type":"markdown","source":["Like in the last notebook, we can use `__version__` to check the `PyTorch` version that Colab is running on."],"metadata":{"id":"B6S-n3L-_Ovm"},"id":"B6S-n3L-_Ovm"},{"cell_type":"code","source":["torch.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"g1iRWzuA_MGt","executionInfo":{"status":"ok","timestamp":1744881006984,"user_tz":-120,"elapsed":39,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"92837fcb-b8ac-406c-c603-70b98fa7e1cf"},"id":"g1iRWzuA_MGt","execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.6.0+cu124'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","id":"adjacent-hearing","metadata":{"id":"adjacent-hearing"},"source":["PyTorch is open source and the documentation can he accessed [here](https://pytorch.org/docs/stable/index.html). With it imported, we can get started!"]},{"cell_type":"markdown","source":["## Tensors\n","\n","Tensors are the most basic building blocks in `PyTorch`. Tensors are similar to matrices, but the have extra properties and they can represent higher dimensions. For example, an square RGB image with 256 pixels in both sides can be represented by a 3x256x256 tensor, where the first 3 dimensions represent the color channels RGB. In `PyTorch`, we often use tensors to encode the inputs and outputs of a neural network model, as well as the model's parameters, to a numeric format which can be understood by the architecture. Tensors can run on GPU's to accelerate e.g. network training."],"metadata":{"id":"5Bsa9mtl_f_v"},"id":"5Bsa9mtl_f_v"},{"cell_type":"markdown","source":["### Tensor Initialization"],"metadata":{"id":"RJTV9cfdAAah"},"id":"RJTV9cfdAAah"},{"cell_type":"markdown","source":["There are several ways to instantiate tensors:\n","\n","**Directly from data**\n","\n","Tensors can be created directly from data. The data type is\n","automatically inferred."],"metadata":{"id":"r-cHMa9jAEDG"},"id":"r-cHMa9jAEDG"},{"cell_type":"code","source":["data = [[1, 2], [3, 4]]\n","x_data = torch.tensor(data)\n","x_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vZjm8c5YAgVu","executionInfo":{"status":"ok","timestamp":1744881301741,"user_tz":-120,"elapsed":27,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"cb839b1b-10a5-42b8-dd45-f22d10361c25"},"id":"vZjm8c5YAgVu","execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["print(type(x_data)) # prints the type of the data structure, i.e. tensor\n","print(x_data.dtype) # print type of elements in the tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1IRvL6CAk0P","executionInfo":{"status":"ok","timestamp":1744881309900,"user_tz":-120,"elapsed":20,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"0718f215-bf5b-4596-e962-525f7aba597d"},"id":"W1IRvL6CAk0P","execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n","torch.int64\n"]}]},{"cell_type":"markdown","source":["We can also speficy the data type (`dtype`) directly:"],"metadata":{"id":"eAZf8_8wCCOn"},"id":"eAZf8_8wCCOn"},{"cell_type":"code","source":["# We are using the dtype to create a float tensor\n","x_float = torch.tensor(data, dtype=torch.float)\n","x_float.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LseoNwzFCIMo","executionInfo":{"status":"ok","timestamp":1744881377622,"user_tz":-120,"elapsed":28,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"b1e7b220-3f2b-49eb-b610-a80c4c98cf88"},"id":"LseoNwzFCIMo","execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.float32"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["**From a Python List**\n","\n","We can initalize a tensor from a Python list, which could include sublists. The dimensions and the data types will be automatically inferred by PyTorch when we use torch.tensor()."],"metadata":{"id":"fQLpeHe9BPtn"},"id":"fQLpeHe9BPtn"},{"cell_type":"code","source":["# Initialize a tensor from a Python List\n","data = [\n","        [0, 1],\n","        [2, 3],\n","        [4, 5]\n","       ]\n","x_python = torch.tensor(data)\n","\n","# Print the tensor\n","x_python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"or-i0liiBYjP","executionInfo":{"status":"ok","timestamp":1744881162697,"user_tz":-120,"elapsed":38,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"fd2d9328-049f-4651-a38d-592b71c21ebf"},"id":"or-i0liiBYjP","execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 1],\n","        [2, 3],\n","        [4, 5]])"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["**From a NumPy array**\n","\n","Tensors can be created from NumPy arrays (and vice versa)."],"metadata":{"id":"t9GTBZTUAoiz"},"id":"t9GTBZTUAoiz"},{"cell_type":"code","source":["np_array = np.array(data)\n","x_np = torch.from_numpy(np_array)\n","x_np"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2nb-2l9CAuIH","executionInfo":{"status":"ok","timestamp":1744881010199,"user_tz":-120,"elapsed":15,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"744b9fbf-8db4-4615-ac13-b8575d1054f3"},"id":"2nb-2l9CAuIH","execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["**From another tensor:**\n","\n","The new tensor retains the properties (shape, datatype) of the argument\n","tensor, unless explicitly overridden."],"metadata":{"id":"ZXF_6JMTA39e"},"id":"ZXF_6JMTA39e"},{"cell_type":"code","source":["x_ones = torch.ones_like(x_data) # retains the properties of x_data\n","print(f\"Ones Tensor: \\n {x_ones} \\n\")\n","\n","x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n","print(f\"Random Tensor: \\n {x_rand} \\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LzdOoITTA6cO","executionInfo":{"status":"ok","timestamp":1744881038599,"user_tz":-120,"elapsed":95,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"d67aa7c5-0f2e-4c92-9fe1-b5683f262ed7"},"id":"LzdOoITTA6cO","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Ones Tensor: \n"," tensor([[1, 1],\n","        [1, 1]]) \n","\n","Random Tensor: \n"," tensor([[0.2647, 0.2573],\n","        [0.7728, 0.3872]]) \n","\n"]}]},{"cell_type":"markdown","source":["**With random or constant values:**\n","\n","Similar to what we have seen with NumPy, we can pre-fill tensors with static values like 1, or random numbers, just such that we have the shape as a placeholder. For this, we define `shape` as a tuple of tensor dimensions. In the functions below, it\n","determines the dimensionality of the output tensor."],"metadata":{"id":"uuMlNkLGCxWX"},"id":"uuMlNkLGCxWX"},{"cell_type":"code","source":["shape = (2, 3,) # 2x3x1 = 2x3 tensor\n","rand_tensor = torch.rand(shape)\n","ones_tensor = torch.ones(shape)\n","zeros_tensor = torch.zeros(shape)\n","\n","print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n","print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n","print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n","\n","# to read the dimensions of a tensor, use shape or size()\n","print(zeros_tensor.shape)\n","print(zeros_tensor.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tzjbYjrwCyMw","executionInfo":{"status":"ok","timestamp":1744881731397,"user_tz":-120,"elapsed":33,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"d6b9e30e-6af2-42b4-c5c5-6fa2f99eaf52"},"id":"tzjbYjrwCyMw","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Tensor: \n"," tensor([[0.4318, 0.0143, 0.3679],\n","        [0.8153, 0.1362, 0.0358]]) \n","\n","Ones Tensor: \n"," tensor([[1., 1., 1.],\n","        [1., 1., 1.]]) \n","\n","Zeros Tensor: \n"," tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n","torch.Size([2, 3])\n","torch.Size([2, 3])\n"]}]},{"cell_type":"markdown","source":["### Tensor Attributes\n","\n","Tensors have several attributes which are important to know and adjust to your needs. Some of these properties are the aforementioned `shape`, `dtype` and the `device` they are stored on. The device could for instance be a CPU or a GPU. During training of neural networks, we might want to push our tensors onto the GPU device for accelerated training. Let's look at these tensor attributes below:"],"metadata":{"id":"xlOE3n1fDvG_"},"id":"xlOE3n1fDvG_"},{"cell_type":"code","source":[],"metadata":{"id":"cmN7lbeDELzY"},"id":"cmN7lbeDELzY","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"cs224n","language":"python","name":"cs224n"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}